
@inproceedings{carton_audience_2015,
	title = {Audience {Analysis} for {Competing} {Memes} in {Social} {Media}},
	copyright = {Authors who publish a paper in this conference agree to the following terms:    1. Author(s) agree to transfer their copyrights in their article/paper to the Association for the Advancement of Artificial Intelligence (AAAI), in order to deal with future requests for reprints, translations, anthologies, reproductions, excerpts, and other publications. This grant will include, without limitation, the entire copyright in the article/paper in all countries of the world, including all renewals, extensions, and reversions thereof, whether such rights current exist or hereafter come into effect, and also the exclusive right to create electronic versions of the article/paper, to the extent that such right is not subsumed under copyright.    2. The author(s) warrants that they are the sole author and owner of the copyright in the above article/paper, except for those portions shown to be in quotations; that the article/paper is original throughout; and that the undersigned right to make the grants set forth above is complete and unencumbered.    3. The author(s) agree that if anyone brings any claim or action alleging facts that, if true, constitute a breach of any of the foregoing warranties, the author(s) will hold harmless and indemnify AAAI, their grantees, their licensees, and their distributors against any liability, whether under judgment, decree, or compromise, and any legal fees and expenses arising out of that claim or actions, and the undersigned will cooperate fully in any defense AAAI may make to such claim or action. Moreover, the undersigned agrees to cooperate in any claim or other action seeking to protect or enforce any right the undersigned has granted to AAAI in the article/paper. If any such claim or action fails because of facts that constitute a breach of any of the foregoing warranties, the undersigned agrees to reimburse whomever brings such claim or action for expenses and attorneys’ fees incurred therein.    4. Author(s) retain all proprietary rights other than copyright (such as patent rights).    5. Author(s) may make personal reuse of all or portions of the above article/paper in other works of their own authorship.    6. Author(s) may reproduce, or have reproduced, their article/paper for the author’s personal use, or for company use provided that AAAI copyright and the source are indicated, and that the copies are not used in a way that implies AAAI endorsement of a product or service of an employer, and that the copies per se are not offered for sale. The foregoing right shall not permit the posting of the article/paper in electronic or digital form on any computer network, except by the author or the author’s employer, and then only on the author’s or the employer’s own web page or ftp site. Such web page or ftp site, in addition to the aforementioned requirements of this Paragraph, must provide an electronic reference or link back to the AAAI electronic server, and shall not post other AAAI copyrighted materials not of the author’s or the employer’s creation (including tables of contents with links to other papers) without AAAI’s written permission.    7. Author(s) may make limited distribution of all or portions of their article/paper prior to publication.    8. In the case of work performed under U.S. Government contract, AAAI grants the U.S. Government royalty-free permission to reproduce all or portions of the above article/paper, and to authorize others to do so, for U.S. Government purposes.    9. In the event the above article/paper is not accepted and published by AAAI, or is withdrawn by the author(s) before acceptance by AAAI, this agreement becomes null and void.},
	url = {https://www.aaai.org/ocs/index.php/ICWSM/ICWSM15/paper/view/10592},
	abstract = {Existing tools for exploratory analysis of information diffusion in social media focus on the message senders who actively diffuse the meme. We develop a tool for audience analysis, focusing on the people who are passively exposed to the messages, with a special emphasis on competing memes such as propagations and corrections of a rumor. In such competing meme diffusions, important questions include which meme reached a bigger total audience, the overlap in audiences of the two, and whether exposure to one meme inhibited propagation of the other. We track audience members’ states of interaction, such as having been exposed to one meme or another or both. We analyze the marginal impact of each message in terms of the number of people who transition between states as a result of that message. These marginal impacts can be computed efficiently, even for diffusions involving thousands of senders and millions of receivers. The marginal impacts provide the raw material for an interactive tool, RumorLens, that includes a Sankey diagram and a network diagram. We validate the utility of the tool through a case study of nine rumor diffusions. We validate the usability of the tool through a user study, showing that nonexperts are able to use it to answer audience analysis questions.},
	language = {en},
	urldate = {2018-12-04},
	booktitle = {Proceedings of the {Ninth} {International} {AAAI} {Conference} on {Web} and {Social} {Media} ({ICWSM})},
	author = {Carton, Samuel and Park, Souneil and Zeffer, Nicole and Adar, Eytan and Mei, Qiaozhu and Resnick, Paul},
	month = apr,
	year = {2015},
	keywords = {Key paper, Interpretable ML evaluation technique},
	file = {Carton et al. - 2015 - Audience Analysis for Competing Memes in Social Me.pdf:C\:\\Users\\scart\\Documents\\Zotero data\\storage\\PY3SV7RZ\\Carton et al. - 2015 - Audience Analysis for Competing Memes in Social Me.pdf:application/pdf;Snapshot:C\:\\Users\\scart\\Documents\\Zotero data\\storage\\S5MB6EYE\\10592.html:text/html},
}

@inproceedings{bao_omnipedia:_2012,
	address = {Austin, Texas, USA},
	title = {Omnipedia: bridging the wikipedia language gap},
	isbn = {978-1-4503-1015-4},
	shorttitle = {Omnipedia},
	url = {http://dl.acm.org/citation.cfm?doid=2207676.2208553},
	doi = {10.1145/2207676.2208553},
	abstract = {We present Omnipedia, a system that allows Wikipedia readers to gain insight from up to 25 language editions of Wikipedia simultaneously. Omnipedia highlights the similarities and differences that exist among Wikipedia language editions, and makes salient information that is unique to each language as well as that which is shared more widely. We detail solutions to numerous front-end and algorithmic challenges inherent to providing users with a multilingual Wikipedia experience. These include visualizing content in a language-neutral way and aligning data in the face of diverse information organization strategies. We present a study of Omnipedia that characterizes how people interact with information using a multilingual lens. We found that users actively sought information exclusive to unfamiliar language editions and strategically compared how language editions defined concepts. Finally, we briefly discuss how Omnipedia generalizes to other domains facing language barriers.},
	language = {en},
	urldate = {2018-12-07},
	booktitle = {Proceedings of the 2012 {ACM} annual conference on {Human} {Factors} in {Computing} {Systems} ({CHI})},
	publisher = {ACM Press},
	author = {Bao, Patti and Hecht, Brent and Carton, Samuel and Quaderi, Mahmood and Horn, Michael and Gergle, Darren},
	year = {2012},
	pages = {1075},
	file = {Bao et al. - 2012 - Omnipedia bridging the wikipedia language gap.pdf:C\:\\Users\\scart\\Documents\\Zotero data\\storage\\KZXUJ8DX\\Bao et al. - 2012 - Omnipedia bridging the wikipedia language gap.pdf:application/pdf},
}

@inproceedings{hecht_explanatory_2012,
	address = {Portland, Oregon, USA},
	title = {Explanatory semantic relatedness and explicit spatialization for exploratory search},
	isbn = {978-1-4503-1472-5},
	url = {http://dl.acm.org/citation.cfm?doid=2348283.2348341},
	doi = {10.1145/2348283.2348341},
	abstract = {Exploratory search, in which a user investigates complex concepts, is cumbersome with today’s search engines. We present a new exploratory search approach that generates interactive visualizations of query concepts using thematic cartography (e.g. choropleth maps, heat maps). We show how the approach can be applied broadly across both geographic and non-geographic contexts through explicit spatialization, a novel method that leverages any figure or diagram – from a periodic table, to a parliamentary seating chart, to a world map – as a spatial search environment. We enable this capability by introducing explanatory semantic relatedness measures. These measures extend frequently-used semantic relatedness measures to not only estimate the degree of relatedness between two concepts, but also generate human-readable explanations for their estimates by mining Wikipedia’s text, hyperlinks, and category structure. We implement our approach in a system called Atlasify, evaluate its key components, and present several use cases.},
	language = {en},
	urldate = {2018-12-07},
	booktitle = {Proceedings of the 35th international {ACM} {SIGIR} conference on {Research} and development in information retrieval ({SIGIR})},
	publisher = {ACM Press},
	author = {Hecht, Brent and Carton, Samuel H. and Quaderi, Mahmood and Schöning, Johannes and Raubal, Martin and Gergle, Darren and Downey, Doug},
	year = {2012},
	pages = {415},
	file = {Hecht et al. - 2012 - Explanatory semantic relatedness and explicit spat.pdf:C\:\\Users\\scart\\Documents\\Zotero data\\storage\\9CFZ4HHZ\\Hecht et al. - 2012 - Explanatory semantic relatedness and explicit spat.pdf:application/pdf},
}

@article{helsby_early_2018,
	title = {Early {Intervention} {Systems}: {Predicting} {Adverse} {Interactions} {Between} {Police} and the {Public}},
	volume = {29},
	issn = {0887-4034, 1552-3586},
	shorttitle = {Early {Intervention} {Systems}},
	url = {http://journals.sagepub.com/doi/10.1177/0887403417695380},
	doi = {10.1177/0887403417695380},
	abstract = {Adverse interactions between police and the public hurt police legitimacy, cause harm to both officers and the public, and result in costly litigation. Early intervention systems (EISs) that flag officers considered most likely to be involved in one of these adverse events are an important tool for police supervision and for targeting interventions such as counseling or training. However, the EISs that exist are not data-driven and based on supervisor intuition. We have developed a data-driven EIS that uses a diverse set of data sources from the Charlotte-Mecklenburg Police Department and machine learning techniques to more accurately predict the officers who will have an adverse event. Our approach is able to significantly improve accuracy compared with their existing EIS: Preliminary results indicate a 20\% reduction in false positives and a 75\% increase in true positives.},
	language = {en},
	number = {2},
	urldate = {2018-12-07},
	journal = {Criminal Justice Policy Review},
	author = {Helsby, Jennifer and Carton, Samuel and Joseph, Kenneth and Mahmud, Ayesha and Park, Youngsoo and Navarrete, Andrea and Ackermann, Klaus and Walsh, Joe and Haynes, Lauren and Cody, Crystal and Patterson, Major Estella and Ghani, Rayid},
	month = mar,
	year = {2018},
	pages = {190--209},
	file = {Helsby et al. - 2018 - Early Intervention Systems Predicting Adverse Int.pdf:C\:\\Users\\scart\\Documents\\Zotero data\\storage\\355DKXK8\\Helsby et al. - 2018 - Early Intervention Systems Predicting Adverse Int.pdf:application/pdf},
}

@inproceedings{resnick_rumorlens:_2014,
	title = {{RumorLens}: {A} {System} for {Analyzing} the {Impact} of {Rumors} and {Corrections} in {Social} {Media}},
	abstract = {Some rumors spread quickly and widely through social media. Journalists write about them, both to help the public understand whether they are true, and to help the public understand how widely misinformation and corrections have spread, and how they did. We describe RumorLens, a suite of interactive tools that are designed to help journalists identify new rumors on Twitter and assess the audiences that rumor and correction tweets have reached. The tools make efficient use of human labor to assess whether a rumor’s content is interesting enough to warrant further exploration, to label tweets as spreading, correcting, or unrelated to the rumor, and to analyze the rumor visually. Behind the scenes, automated learning and computation amplifies the effectiveness of that labor, making it feasible to engage journalists and the broader public to run a continuous rumor-monitoring service.},
	language = {en},
	booktitle = {Proceedings of the {Computation} + {Journalism} {Symposium}},
	author = {Resnick, Paul and Carton, Samuel and Park, Souneil and Shen, Yuncheng and Zeffer, Nicole},
	year = {2014},
	pages = {5},
	file = {Resnick et al. - 2014 - RumorLens A System for Analyzing the Impact of Ru.pdf:C\:\\Users\\scart\\Documents\\Zotero data\\storage\\3LG45LNA\\Resnick et al. - 2014 - RumorLens A System for Analyzing the Impact of Ru.pdf:application/pdf},
}

@inproceedings{carton_identifying_2016,
	address = {San Francisco, California, USA},
	title = {Identifying {Police} {Officers} at {Risk} of {Adverse} {Events}},
	isbn = {978-1-4503-4232-2},
	url = {http://dl.acm.org/citation.cfm?doid=2939672.2939698},
	doi = {10.1145/2939672.2939698},
	abstract = {Adverse events between police and the public, such as deadly shootings or instances of racial proﬁling, can cause serious or deadly harm, damage police legitimacy, and result in costly litigation. Evidence suggests these events can be prevented by targeting interventions based on an Early Intervention System (EIS) that ﬂags police oﬃcers who are at a high risk for involvement in such adverse events. Today’s EIS are not data-driven and typically rely on simple thresholds based entirely on expert intuition. In this paper, we describe our work with the Charlotte-Mecklenburg Police Department (CMPD) to develop a machine learning model to predict which oﬃcers are at risk for an adverse event. Our approach signiﬁcantly outperforms CMPD’s existing EIS, increasing true positives by ∼ 12\% and decreasing false positives by ∼ 32\%. Our work also sheds light on features related to oﬃcer characteristics, situational factors, and neighborhood factors that are predictive of adverse events. This work provides a starting point for police departments to take a comprehensive, data-driven approach to improve policing and reduce harm to both oﬃcers and members of the public.},
	language = {en},
	urldate = {2018-12-07},
	booktitle = {Proceedings of the 22nd {ACM} {SIGKDD} {International} {Conference} on {Knowledge} {Discovery} and {Data} {Mining} ({KDD})},
	publisher = {ACM Press},
	author = {Carton, Samuel and Ghani, Rayid and Helsby, Jennifer and Joseph, Kenneth and Mahmud, Ayesha and Park, Youngsoo and Walsh, Joe and Cody, Crystal and Patterson, CPT Estella and Haynes, Lauren},
	year = {2016},
	pages = {67--76},
	file = {Carton et al. - 2016 - Identifying Police Officers at Risk of Adverse Eve.pdf:C\:\\Users\\scart\\Documents\\Zotero data\\storage\\V99SMX6T\\Carton et al. - 2016 - Identifying Police Officers at Risk of Adverse Eve.pdf:application/pdf},
}

@inproceedings{carton_feature-based_2020,
	title = {Feature-{Based} {Explanations} {Don}'t {Help} {People} {Detect} {Misclassifications} of {Online} {Toxicity}},
	volume = {14},
	copyright = {Copyright (c) 2020 Association for the Advancement of Artificial Intelligence},
	url = {https://aaai.org/ojs/index.php/ICWSM/article/view/7282},
	abstract = {We present an experimental assessment of the impact of feature attribution-style explanations on human performance in predicting the consensus toxicity of social media posts with advice from an unreliable machine learning model. By doing so we add to a small but growing body of literature inspecting the utility of interpretable machine learning in terms of human outcomes. We also evaluate interpretable machine learning for the first time in the important domain of online toxicity, where fully-automated methods have faced criticism as being inadequate as a measure of toxic behavior.We find that, contrary to expectations, explanations have no significant impact on accuracy or agreement with model predictions, through they do change the distribution of subject error somewhat while reducing the cognitive burden of the task for subjects. Our results contribute to the recognition of an intriguing expectation gap in the field of interpretable machine learning between the general excitement the field has engendered and the ambiguous results of recent experimental work, including this study.},
	language = {en},
	urldate = {2020-06-09},
	booktitle = {Proceedings of the {International} {AAAI} {Conference} on {Web} and {Social} {Media} ({ICWSM})},
	author = {Carton, Samuel and Mei, Qiaozhu and Resnick, Paul},
	month = may,
	year = {2020},
	pages = {95--106},
	file = {Carton et al. - 2020 - Feature-Based Explanations Don't Help People Detec.pdf:C\:\\Users\\scart\\Documents\\Zotero data\\storage\\RUTN9QAA\\Carton et al. - 2020 - Feature-Based Explanations Don't Help People Detec.pdf:application/pdf;Full Text PDF:C\:\\Users\\scart\\Documents\\Zotero data\\storage\\4ZECFYB3\\Carton et al. - 2020 - Feature-Based Explanations Don't Help People Detec.pdf:application/pdf;FULL-CartonS.1077.pdf:C\:\\Users\\scart\\Documents\\Zotero data\\storage\\JA96VSNW\\FULL-CartonS.1077.pdf:application/pdf;Snapshot:C\:\\Users\\scart\\Documents\\Zotero data\\storage\\SXDIVFMQ\\7282.html:text/html},
}

@inproceedings{carton_evaluating_2020,
	address = {Online},
	title = {Evaluating and {Characterizing} {Human} {Rationales}},
	url = {https://www.aclweb.org/anthology/2020.emnlp-main.747},
	doi = {10.18653/v1/2020.emnlp-main.747},
	abstract = {Two main approaches for evaluating the quality of machine-generated rationales are: 1) using human rationales as a gold standard; and 2) automated metrics based on how rationales affect model behavior. An open question, however, is how human rationales fare with these automatic metrics. Analyzing a variety of datasets and models, we find that human rationales do not necessarily perform well on these metrics. To unpack this finding, we propose improved metrics to account for model-dependent baseline performance. We then propose two methods to further characterize rationale quality, one based on model retraining and one on using “fidelity curves” to reveal properties such as irrelevance and redundancy. Our work leads to actionable suggestions for evaluating and characterizing rationales.},
	urldate = {2021-05-16},
	booktitle = {Proceedings of the 2020 {Conference} on {Empirical} {Methods} in {Natural} {Language} {Processing} ({EMNLP})},
	publisher = {Association for Computational Linguistics},
	author = {Carton, Samuel and Rathore, Anirudh and Tan, Chenhao},
	month = nov,
	year = {2020},
	pages = {9294--9307},
	file = {Full Text PDF:C\:\\Users\\scart\\Documents\\Zotero data\\storage\\DYJMIFHL\\Carton et al. - 2020 - Evaluating and Characterizing Human Rationales.pdf:application/pdf},
}

@inproceedings{garbacea_explainable_2021,
	address = {Online},
	title = {Explainable {Prediction} of {Text} {Complexity}: {The} {Missing} {Preliminaries} for {Text} {Simplification}},
	shorttitle = {Explainable {Prediction} of {Text} {Complexity}},
	url = {https://aclanthology.org/2021.acl-long.88},
	doi = {10.18653/v1/2021.acl-long.88},
	abstract = {Text simplification reduces the language complexity of professional content for accessibility purposes. End-to-end neural network models have been widely adopted to directly generate the simplified version of input text, usually functioning as a blackbox. We show that text simplification can be decomposed into a compact pipeline of tasks to ensure the transparency and explainability of the process. The first two steps in this pipeline are often neglected: 1) to predict whether a given piece of text needs to be simplified, and 2) if yes, to identify complex parts of the text. The two tasks can be solved separately using either lexical or deep learning methods, or solved jointly. Simply applying explainable complexity prediction as a preliminary step, the out-of-sample text simplification performance of the state-of-the-art, black-box simplification models can be improved by a large margin.},
	urldate = {2021-10-27},
	booktitle = {Proceedings of the 59th {Annual} {Meeting} of the {Association} for {Computational} {Linguistics} ({ACL})},
	publisher = {Association for Computational Linguistics},
	author = {Garbacea, Cristina and Guo, Mengtian and Carton, Samuel and Mei, Qiaozhu},
	month = aug,
	year = {2021},
	pages = {1086--1097},
	file = {Full Text PDF:C\:\\Users\\scart\\Documents\\Zotero data\\storage\\49XL5CJD\\Garbacea et al. - 2021 - Explainable Prediction of Text Complexity The Mis.pdf:application/pdf},
}

@article{carton_what_2022,
	title = {What to {Learn}, and {How}: {Toward} {Effective} {Learning} from {Rationales}},
	journal = {Findings of the Association for Computational Linguistics (ACL)},
	author = {Carton, Samuel and Kanoria, Surya and Tan, Chenhao},
	year = {2022},
	file = {Carton et al. - 2022 - What to Learn, and How Toward Effective Learning .pdf:C\:\\Users\\scart\\Documents\\Zotero data\\storage\\7BKZ9X7G\\Carton et al. - 2022 - What to Learn, and How Toward Effective Learning .pdf:application/pdf},
}

@inproceedings{lai_harnessing_2020,
	title = {Harnessing {Explanations} to {Bridge} {AI} and {Humans}},
	url = {http://arxiv.org/abs/2003.07370},
	abstract = {Machine learning models are increasingly integrated into societally critical applications such as recidivism prediction and medical diagnosis, thanks to their superior predictive power. In these applications, however, full automation is often not desired due to ethical and legal concerns. The research community has thus ventured into developing interpretable methods that explain machine predictions. While these explanations are meant to assist humans in understanding machine predictions and thereby allowing humans to make better decisions, this hypothesis is not supported in many recent studies. To improve human decision-making with AI assistance, we propose future directions for closing the gap between the efficacy of explanations and improvement in human performance.},
	urldate = {2021-10-28},
	booktitle = {Proceedings of the {CHI} 2020 {Fair} \& {Responsible} {AI} {Workshop}},
	author = {Lai, Vivian and Carton, Samuel and Tan, Chenhao},
	month = mar,
	year = {2020},
	note = {arXiv: 2003.07370},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language, Computer Science - Computers and Society, Computer Science - Human-Computer Interaction},
	file = {arXiv Fulltext PDF:C\:\\Users\\scart\\Documents\\Zotero data\\storage\\LAWN2VZ5\\Lai et al. - 2020 - Harnessing Explanations to Bridge AI and Humans.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\scart\\Documents\\Zotero data\\storage\\22IXSLQR\\2003.html:text/html},
}

@inproceedings{garbacea_judge_2019,
	address = {Hong Kong, China},
	title = {Judge the {Judges}: {A} {Large}-{Scale} {Evaluation} {Study} of {Neural} {Language} {Models} for {Online} {Review} {Generation}},
	shorttitle = {Judge the {Judges}},
	url = {https://aclanthology.org/D19-1409},
	doi = {10.18653/v1/D19-1409},
	abstract = {We conduct a large-scale, systematic study to evaluate the existing evaluation methods for natural language generation in the context of generating online product reviews. We compare human-based evaluators with a variety of automated evaluation procedures, including discriminative evaluators that measure how well machine-generated text can be distinguished from human-written text, as well as word overlap metrics that assess how similar the generated text compares to human-written references. We determine to what extent these different evaluators agree on the ranking of a dozen of state-of-the-art generators for online product reviews. We find that human evaluators do not correlate well with discriminative evaluators, leaving a bigger question of whether adversarial accuracy is the correct objective for natural language generation. In general, distinguishing machine-generated text is challenging even for human evaluators, and human decisions correlate better with lexical overlaps. We find lexical diversity an intriguing metric that is indicative of the assessments of different evaluators. A post-experiment survey of participants provides insights into how to evaluate and improve the quality of natural language generation systems.},
	urldate = {2021-11-06},
	booktitle = {Proceedings of the 2019 {Conference} on {Empirical} {Methods} in {Natural} {Language} {Processing} ({EMNLP})},
	publisher = {Association for Computational Linguistics},
	author = {Garbacea, Cristina and Carton, Samuel and Yan, Shiyan and Mei, Qiaozhu},
	month = nov,
	year = {2019},
	pages = {3968--3981},
	file = {Full Text PDF:C\:\\Users\\scart\\Documents\\Zotero data\\storage\\J4KY5PD8\\Garbacea et al. - 2019 - Judge the Judges A Large-Scale Evaluation Study o.pdf:application/pdf},
}

@inproceedings{carton_extractive_2018,
	address = {Brussels, Belgium},
	title = {Extractive {Adversarial} {Networks}: {High}-{Recall} {Explanations} for {Identifying} {Personal} {Attacks} in {Social} {Media} {Posts}},
	shorttitle = {Extractive {Adversarial} {Networks}},
	url = {https://aclanthology.org/D18-1386},
	doi = {10.18653/v1/D18-1386},
	abstract = {We introduce an adversarial method for producing high-recall explanations of neural text classifier decisions. Building on an existing architecture for extractive explanations via hard attention, we add an adversarial layer which scans the residual of the attention for remaining predictive signal. Motivated by the important domain of detecting personal attacks in social media comments, we additionally demonstrate the importance of manually setting a semantically appropriate “default” behavior for the model by explicitly manipulating its bias term. We develop a validation set of human-annotated personal attacks to evaluate the impact of these changes.},
	urldate = {2021-11-06},
	booktitle = {Proceedings of the 2018 {Conference} on {Empirical} {Methods} in {Natural} {Language} {Processing} ({EMNLP})},
	publisher = {Association for Computational Linguistics},
	author = {Carton, Samuel and Mei, Qiaozhu and Resnick, Paul},
	month = oct,
	year = {2018},
	pages = {3497--3507},
	file = {Full Text PDF:C\:\\Users\\scart\\Documents\\Zotero data\\storage\\CUPG6RXF\\Carton et al. - 2018 - Extractive Adversarial Networks High-Recall Expla.pdf:application/pdf},
}

@inproceedings{lai_human-ai_2022,
	title = {Human-{AI} {Collaboration} via {Conditional} {Delegation}: {A} {Case} {Study} of {Content} {Moderation}},
	abstract = {Despite impressive performance in many benchmark datasets, AI models can still make mistakes, especially among out-of-distribution examples. It remains an open question how such imperfect models can be used effectively in collaboration with humans. Prior work has focused on AI assistance that helps people make individual high-stakes decisions, which is not scalable for a large amount of relatively low-stakes decisions, e.g., moderating social media comments. Instead, we propose conditional delegation as an alternative paradigm for human-AI collaboration where humans create rules to indicate trustworthy regions of a model. Using content moderation as a testbed, we develop novel interfaces to assist humans in creating conditional delegation rules and conduct a randomized experiment with two datasets to simulate in-distribution and outof-distribution scenarios. Our study demonstrates the promise of conditional delegation in improving model performance and provides insights into design for this novel paradigm, including the effect of AI explanations.},
	language = {en},
	booktitle = {Proceedings of the 2022 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	author = {Lai, Vivian and Carton, Samuel and Bhatnagar, Rajat and Liao, Q Vera and Zhang, Yunfeng and Tan, Chenhao},
	year = {2022},
	pages = {18},
	file = {Lai et al. - 2022 - Human-AI Collaboration via Conditional Delegation.pdf:C\:\\Users\\scart\\Documents\\Zotero data\\storage\\XTLLJ24U\\Lai et al. - 2022 - Human-AI Collaboration via Conditional Delegation.pdf:application/pdf},
}

@article{tang_context-aware_2016,
	title = {Context-aware {Natural} {Language} {Generation} with {Recurrent} {Neural} {Networks}},
	url = {http://arxiv.org/abs/1611.09900},
	abstract = {This paper studied generating natural languages at particular contexts or situations. We proposed two novel approaches which encode the contexts into a continuous semantic representation and then decode the semantic representation into text sequences with recurrent neural networks. During decoding, the context information are attended through a gating mechanism, addressing the problem of long-range dependency caused by lengthy sequences. We evaluate the effectiveness of the proposed approaches on user review data, in which rich contexts are available and two informative contexts, sentiments and products, are selected for evaluation. Experiments show that the fake reviews generated by our approaches are very natural. Results of fake review detection with human judges show that more than 50\% of the fake reviews are misclassiﬁed as the real reviews, and more than 90\% are misclassiﬁed by existing state-of-the-art fake review detection algorithm.},
	language = {en},
	urldate = {2022-03-17},
	journal = {arXiv preprint},
	author = {Tang, Jian and Yang, Yifan and Carton, Sam and Zhang, Ming and Mei, Qiaozhu},
	month = nov,
	year = {2016},
	note = {arXiv: 1611.09900},
	keywords = {Computer Science - Computation and Language},
	file = {Tang et al. - 2016 - Context-aware Natural Language Generation with Rec.pdf:C\:\\Users\\scart\\Documents\\Zotero data\\storage\\43C2KZ54\\Tang et al. - 2016 - Context-aware Natural Language Generation with Rec.pdf:application/pdf},
}
